ðŸŽ¤ Microphone
   â”‚ (MediaStream)
   â–¼
Main AudioContext (audioContextRef)
   â”‚
   â”œâ”€â–¶ createMediaStreamSource(stream)
   â”‚       â”‚
   â”‚       â”œâ”€â–¶ AudioWorkletNode ("pcm-processor")
   â”‚       â”‚       â”‚
   â”‚       â”‚       â””â”€â–¶ port.onmessage â†’ PCM data
   â”‚       â”‚                     â”‚
   â”‚       â”‚                     â””â”€â–¶ DataChannel â†’ OpenAI (send mic audio)
   â”‚       â”‚
   â”‚       â””â”€â–¶ AnalyserNode (mic VAD / visualization)
   â”‚
   â””â”€ (no direct playback here)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ðŸ¤– OpenAI (via WebRTC PeerConnection)
   â”‚
   â–¼
Remote Audio Track (MediaStream)
   â”‚
   â”œâ”€â–¶ <audio> element (autoplay â†’ speakers)  
   â”‚
   â””â”€â–¶ AI AudioContext (aiAudioContext)
           â”‚
           â”œâ”€â–¶ createMediaStreamSource(remoteStream)
           â”‚       â”‚
           â”‚       â””â”€â–¶ AnalyserNode (AI VAD)
           â”‚                  â”‚
           â”‚                  â””â”€â–¶ Detect if AI is speaking
           â”‚                          (pause mic sending to avoid echo)
           â”‚
           â””â”€ (no worklet here, just analysis)
